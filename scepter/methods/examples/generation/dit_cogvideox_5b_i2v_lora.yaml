ENV:
  BACKEND: nccl
  SEED: 42
  TENSOR_PARALLEL_SIZE: 1
  PIPELINE_PARALLEL_SIZE: 1
  SYS_ENVS:
    TORCH_CUDNN_V8_API_ENABLED: '1'
    TOKENIZERS_PARALLELISM: 'false'
    TF_CPP_MIN_LOG_LEVEL: '3'
    PYTORCH_CUDA_ALLOC_CONF: 'expandable_segments:True'
#
SOLVER:
  NAME: LatentDiffusionVideoSolver
  MAX_STEPS: 2000
  USE_AMP: True
  DTYPE: bfloat16
  USE_FAIRSCALE: False
  USE_FSDP: True
  LOAD_MODEL_ONLY: False
  ENABLE_GRADSCALER: False
  USE_SCALER: False
  RESUME_FROM:
  WORK_DIR: ./cache/save_data/dit_cogvideox_5b_i2v_lora
  LOG_FILE: std_log.txt
  EVAL_INTERVAL: 100
  LOG_TRAIN_NUM: 4
  FPS: 8
  SHARDING_STRATEGY: full_shard
  FSDP_REDUCE_DTYPE: float32
  FSDP_BUFFER_DTYPE: float32
  FSDP_SHARD_MODULES: [ 'model', 'cond_stage_model.model']
  SAVE_MODULES: [ 'model', 'cond_stage_model.model']
  TRAIN_MODULES: ['model']
  #
  FILE_SYSTEM:
    NAME: "ModelscopeFs"
    TEMP_DIR: "./cache/cache_data"
  #
  TUNER:
    - NAME: SwiftLoRA
      R: 64
      LORA_ALPHA: 64
      LORA_DROPOUT: 0.0
      BIAS: "none"
      TARGET_MODULES: "model.*(.to_k|.to_q|.to_v|.to_out.0)$"
  #
  MODEL:
    NAME: LatentDiffusionCogVideoX
    PRETRAINED_MODEL:
    PARAMETERIZATION: v
    TIMESTEPS: 1000
    MIN_SNR_GAMMA: 3.0
    ZERO_TERMINAL_SNR: True
    SCALE_FACTOR_SPATIAL: 8
    SCALE_FACTOR_TEMPORAL: 4
    SCALING_FACTOR_IMAGE: 0.7  # 5b diff
    NOISED_IMAGE_DROPOUT: 0.05
    IGNORE_KEYS: [ ]
    DEFAULT_N_PROMPT:
    USE_EMA: False
    EVAL_EMA: False
    DIFFUSION:
      NAME: BaseDiffusion
      PREDICTION_TYPE: v
      NOISE_SCHEDULER:
        NAME: ScaledLinearScheduler
        BETA_MIN: 0.00085
        BETA_MAX: 0.012
        SNR_SHIFT_SCALE: 1.0  # 5b diff
        RESCALE_BETAS_ZERO_SNR: True
      DIFFUSION_SAMPLERS:
        NAME: DDIMSampler
        DISCRETIZATION_TYPE: trailing
        ETA: 0.0
    #
    DIFFUSION_MODEL:
      NAME: CogVideoXTransformer3DModel
      DTYPE: bfloat16
      PRETRAINED_MODEL: # 5b-I2V diff
        - ms://AI-ModelScope/CogVideoX-5b-I2V@transformer/diffusion_pytorch_model-00001-of-00003.safetensors
        - ms://AI-ModelScope/CogVideoX-5b-I2V@transformer/diffusion_pytorch_model-00002-of-00003.safetensors
        - ms://AI-ModelScope/CogVideoX-5b-I2V@transformer/diffusion_pytorch_model-00003-of-00003.safetensors
      NUM_ATTENTION_HEADS: 48  # 5b diff
      ATTENTION_HEAD_DIM: 64
      IN_CHANNELS: 32  # 5b-I2V diff
      LATENT_CHANNELS: 16
      OUT_CHANNELS: 16
      FLIP_SIN_TO_COS: True
      FREQ_SHIFT: 0
      TIME_EMBED_DIM: 512
      TEXT_EMBED_DIM: 4096
      NUM_LAYERS: 42  # 5b diff
      DROPOUT: 0.0
      ATTENTION_BIAS: True
      SAMPLE_WIDTH: 90
      SAMPLE_HEIGHT: 60
      SAMPLE_FRAMES: 49
      PATCH_SIZE: 2
      TEMPORAL_COMPRESSION_RATIO: 4
      MAX_TEXT_SEQ_LENGTH: 226
      ACTIVATION_FN: "gelu-approximate"
      TIMESTEP_ACTIVATION_FN: "silu"
      NORM_ELEMENTWISE_AFFINE: True
      NORM_EPS: 1e-5
      SPATIAL_INTERPOLATION_SCALE: 1.875
      TEMPORAL_INTERPOLATION_SCALE: 1.0
      USE_ROTARY_POSITIONAL_EMBEDDINGS: True # 5b diff
      USE_LEARNED_POSITIONAL_EMBEDDINGS: True  # 5b-I2V diff
      GRADIENT_CHECKPOINTING: True
    #
    FIRST_STAGE_MODEL:
      NAME: AutoencoderKLCogVideoX
      DTYPE: bfloat16
      PRETRAINED_MODEL: ms://AI-ModelScope/CogVideoX-5b-I2V@vae/diffusion_pytorch_model.safetensors # 5b diff
      SAMPLE_HEIGHT: 480
      SAMPLE_WIDTH: 720
      USE_QUANT_CONV: False
      USE_POST_QUANT_CONV: False
      USE_SLICING: True
      USE_TILING: True
      GRADIENT_CHECKPOINTING: True
      ENCODER:
        NAME: CogVideoXEncoder3D
        IN_CHANNELS: 3
        OUT_CHANNELS: 16
        UP_BLOCK_TYPES: [ "CogVideoXDownBlock3D", "CogVideoXDownBlock3D", "CogVideoXDownBlock3D", "CogVideoXDownBlock3D" ]
        BLOCK_OUT_CHANNELS: [ 128, 256, 256, 512 ]
        LAYERS_PER_BLOCK: 3
        ACT_FN: "silu"
        NORM_EPS: 1e-6
        NORM_NUM_GROUPS: 32
        DROPOUT: 0.0
        PAD_MODE: "first"
        TEMPORAL_COMPRESSION_RATIO: 4
        GRADIENT_CHECKPOINTING: True
      DECODER:
        NAME: CogVideoXDecoder3D
        IN_CHANNELS: 16
        OUT_CHANNELS: 3
        UP_BLOCK_TYPES: [ "CogVideoXUpBlock3D", "CogVideoXUpBlock3D", "CogVideoXUpBlock3D", "CogVideoXUpBlock3D" ]
        BLOCK_OUT_CHANNELS: [ 128, 256, 256, 512 ]
        LAYERS_PER_BLOCK: 3
        ACT_FN: "silu"
        NORM_EPS: 1e-6
        NORM_NUM_GROUPS: 32
        DROPOUT: 0.0
        PAD_MODE: "first"
        TEMPORAL_COMPRESSION_RATIO: 4
        GRADIENT_CHECKPOINTING: True
    #
    COND_STAGE_MODEL:
      NAME: T5EmbedderHF
      PRETRAINED_MODEL: ms://AI-ModelScope/t5-v1_1-xxl
      TOKENIZER_PATH: ms://AI-ModelScope/t5-v1_1-xxl
      LENGTH: 226
      CLEAN:
      USE_GRAD: False
    #
    LOSS:
      NAME: ReconstructLoss
      LOSS_TYPE: l2
  #
  SAMPLE_ARGS:
    SAMPLER: ddim
    SAMPLE_STEPS: 50
    SEED: 42
    GUIDE_SCALE: 6.0
    GUIDE_RESCALE: 0.0
    NUM_FRAMES: 49
  #
  OPTIMIZER:
    NAME: Adam
    LEARNING_RATE: 1e-3
    BETAS: [ 0.9, 0.95 ]
    EPS: 1e-8
    WEIGHT_DECAY: 0.0
    AMSGRAD: False
  #
#  LR_SCHEDULER:
#    NAME: StepAnnealingLR
#    WARMUP_STEPS: 200
#    TOTAL_STEPS: 2000
#    DECAY_MODE: 'cosine'
  #
  TRAIN_DATA:
    NAME: VideoGenDataset
    MODE: train
    PIN_MEMORY: True
    BATCH_SIZE: 1
    NUM_WORKERS: 0
    PROMPT_PREFIX: 'DISNEY '
    DATA_TYPE: 'i2v'
    SAMPLER:
      NAME: MixtureOfSamplers
      SUB_SAMPLERS:
        - NAME: MultiLevelBatchSampler
          PROB: 1.0
          FIELDS: [ "video_path", "prompt" ]
          DELIMITER: '#;#'
          PATH_PREFIX: cache/datasets/Disney-VideoGeneration-Dataset/
          INDEX_FILE: cache/datasets/Disney-VideoGeneration-Dataset/index.jsonl
    TRANSFORMS:
      - NAME: Select
        KEYS: [ "video", "image", "prompt" ]
        META_KEYS: [ ]
  #
#  EVAL_DATA:
#    NAME: Text2ImageDataset
#    MODE: eval
#    PROMPT_FILE:
#    PROMPT_DATA: [ "A cat running.#;#asset/images/edit_tuner/cat_512.jpg" ]
#    FIELDS: [ "prompt", "img_path" ]
#    DELIMITER: '#;#'
#    PROMPT_PREFIX: ''
#    PIN_MEMORY: True
#    BATCH_SIZE: 1
#    USE_NUM: 8
#    NUM_WORKERS: 0
#    IMAGE_SIZE: [ 480, 720 ]
#    TRANSFORMS:
#      - NAME: LoadImageFromFileList
#        FILE_KEYS: [ 'img_path' ]
#        RGB_ORDER: RGB
#        BACKEND: pillow
#      - NAME: FlexibleResize
#        INTERPOLATION: bilinear
#        SIZE: [ 480, 720 ]
#        INPUT_KEY: [ 'img' ]
#        OUTPUT_KEY: [ 'img' ]
#        BACKEND: pillow
#      - NAME: FlexibleCenterCrop
#        SIZE: [ 480, 720 ]
#        INPUT_KEY: [ 'img' ]
#        OUTPUT_KEY: [ 'img' ]
#        BACKEND: pillow
#      - NAME: ImageToTensor
#        INPUT_KEY: [ 'img' ]
#        OUTPUT_KEY: [ 'img' ]
#        BACKEND: pillow
#      - NAME: Normalize
#        MEAN: [ 0.5,  0.5,  0.5 ]
#        STD: [ 0.5,  0.5,  0.5 ]
#        INPUT_KEY: [ 'img' ]
#        OUTPUT_KEY: [ 'image' ]
#        BACKEND: torchvision
#      - NAME: Select
#        KEYS: [ 'image', 'prompt' ]
#        META_KEYS: [ 'image_size' ]
  #
  TRAIN_HOOKS:
    - NAME: ProbeDataHook
      PROB_INTERVAL: 100
      PRIORITY: 0
    - NAME: BackwardHook
      PRIORITY: 10
    - NAME: LogHook
      LOG_INTERVAL: 10
      PRIORITY: 20
    - NAME: CheckpointHook
      INTERVAL: 1000
      PRIORITY: 40
  #
#  EVAL_HOOKS:
#    - NAME: ProbeDataHook
#      PROB_INTERVAL: 100
#      PRIORITY: 0